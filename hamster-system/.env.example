# Hamster System - Environment Variables
# Copy this file to .env and fill in your values

# ============================================================================
# API Keys
# ============================================================================

# OpenAI API Key (for synthetic data generation)
OPENAI_API_KEY=sk-...

# Hugging Face Token (for downloading models)
HF_TOKEN=hf_...

# ============================================================================
# API Configuration
# ============================================================================

# Host and Port
HOST=0.0.0.0
PORT=8000

# Debug mode (true/false)
DEBUG=false

# Reload on code changes (development only)
RELOAD=false

# ============================================================================
# Model Configuration
# ============================================================================

# Base model to use
BASE_MODEL_ID=mistralai/Mistral-7B-Instruct-v0.2

# Alternative: Llama 3 8B
# BASE_MODEL_ID=meta-llama/Meta-Llama-3-8B-Instruct

# Adapter directory
ADAPTER_DIR=adapters

# ============================================================================
# Inference Configuration
# ============================================================================

# Maximum tokens to generate
MAX_TOKENS=55

# Temperature for generation (0.0-1.0)
TEMPERATURE=0.1

# Apply post-processing filter
APPLY_FILTER=true

# Device (cuda/cpu/auto)
DEVICE=auto

# ============================================================================
# Training Configuration
# ============================================================================

# Number of training epochs
TRAIN_EPOCHS=3

# Batch size
BATCH_SIZE=4

# Learning rate
LEARNING_RATE=1e-4

# LoRA rank
LORA_R=16

# LoRA alpha
LORA_ALPHA=32

# ============================================================================
# Data Generation
# ============================================================================

# Number of examples per hamster
EXAMPLES_PER_HAMSTER=1000

# OpenAI model for data generation
DATA_GEN_MODEL=gpt-4

# Delay between API calls (seconds)
API_DELAY=0.5
